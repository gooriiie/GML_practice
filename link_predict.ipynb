{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zachery():\n",
    "    nodes_data = pd.read_csv('https://raw.githubusercontent.com/myeonghak/DGL-tutorial/master/data/nodes.csv')\n",
    "    edges_data = pd.read_csv('https://raw.githubusercontent.com/myeonghak/DGL-tutorial/master/data/edges.csv')\n",
    "    src = edges_data['Src'].to_numpy()\n",
    "    dst = edges_data['Dst'].to_numpy()\n",
    "    g = dgl.graph((src, dst))\n",
    "    club = nodes_data['Club'].to_list()\n",
    "    # Convert to categorical integer values with 0 for 'Mr. Hi', 1 for 'Officer'.\n",
    "    club = torch.tensor([c == 'Officer' for c in club]).long()\n",
    "    # We can also convert it to one-hot encoding.\n",
    "    club_onehot = F.one_hot(club)\n",
    "    g.ndata.update({'club' : club, 'club_onehot' : club_onehot})\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=34, num_edges=156,\n",
      "      ndata_schemes={'club': Scheme(shape=(), dtype=torch.int64), 'club_onehot': Scheme(shape=(2,), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1116, -0.3177,  0.1696, -0.3869,  0.0662],\n",
       "        [ 0.1972, -0.1982, -0.1538, -0.2523,  0.0666],\n",
       "        [ 0.2542,  0.3176, -0.1036, -0.2525,  0.1133],\n",
       "        [ 0.0819, -0.3058,  0.0683,  0.1108,  0.0149],\n",
       "        [ 0.3564,  0.3323, -0.1487, -0.3778,  0.3357],\n",
       "        [-0.3220,  0.0835, -0.1055, -0.1706,  0.3823],\n",
       "        [-0.3167, -0.0880,  0.1005, -0.0164,  0.2311],\n",
       "        [-0.3896, -0.1688, -0.0241, -0.0062, -0.2727],\n",
       "        [-0.2042,  0.2344,  0.0678, -0.2126, -0.2960],\n",
       "        [-0.1155,  0.1459,  0.2736, -0.0022, -0.1045],\n",
       "        [ 0.3178, -0.2798,  0.1331, -0.3657, -0.3147],\n",
       "        [ 0.2133, -0.0470,  0.2917,  0.3371, -0.3458],\n",
       "        [ 0.2020,  0.3376,  0.1120, -0.3678,  0.2820],\n",
       "        [ 0.0112, -0.1472, -0.3233, -0.2581, -0.2420],\n",
       "        [-0.2245, -0.0516,  0.3246, -0.1678, -0.3326],\n",
       "        [-0.1589,  0.3127,  0.2259, -0.3833, -0.1675],\n",
       "        [ 0.1974,  0.2712,  0.2815, -0.1448,  0.0526],\n",
       "        [-0.2842, -0.0454, -0.0130, -0.1463,  0.0165],\n",
       "        [-0.1450, -0.3529,  0.0602,  0.3230,  0.0795],\n",
       "        [-0.0429, -0.3337, -0.3022, -0.0817, -0.2219],\n",
       "        [ 0.3820, -0.1429, -0.3661,  0.0776, -0.0777],\n",
       "        [ 0.2507, -0.3740,  0.3287,  0.2633, -0.2003],\n",
       "        [-0.1892,  0.1820,  0.3511, -0.1753, -0.3317],\n",
       "        [-0.1140, -0.0225,  0.0122, -0.3533, -0.1703],\n",
       "        [ 0.3894,  0.2050,  0.1536, -0.3683, -0.3254],\n",
       "        [-0.3542, -0.2937, -0.1587, -0.0411, -0.1873],\n",
       "        [-0.3028, -0.1668,  0.0299, -0.1741,  0.3160],\n",
       "        [ 0.0061, -0.1849, -0.1099, -0.3225,  0.2953],\n",
       "        [-0.2138,  0.0077,  0.2172, -0.0930, -0.3892],\n",
       "        [-0.2913, -0.0672,  0.0671,  0.3882,  0.1645],\n",
       "        [ 0.3381, -0.1328, -0.0678,  0.0779, -0.3193],\n",
       "        [-0.3209, -0.0041, -0.3517, -0.2793,  0.1308],\n",
       "        [ 0.2603,  0.2827, -0.2977, -0.3118, -0.2655],\n",
       "        [ 0.0264, -0.0535, -0.3895,  0.2865,  0.2737]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = load_zachery()\n",
    "print(g)\n",
    "\n",
    "node_embed = nn.Embedding(g.number_of_nodes(), 5)\n",
    "inputs = node_embed.weight\n",
    "nn.init.xavier_uniform_(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = g.edges()\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_pos_u, test_pos_v = u[eids[:50]], v[eids[:50]]\n",
    "train_pos_u, train_pos_v = u[eids[50:]], v[eids[50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(34)\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "neg_eids = np.random.choice(len(neg_u), 200)\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:50]], neg_v[neg_eids[:50]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[50:]], neg_v[neg_eids[50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_u = torch.cat([torch.as_tensor(train_pos_u), torch.as_tensor(train_neg_u)])\n",
    "train_v = torch.cat([torch.as_tensor(train_pos_v), torch.as_tensor(train_neg_v)])\n",
    "train_label = torch.cat([torch.zeros(len(train_pos_u)), torch.ones(len(train_neg_u))])\n",
    "\n",
    "test_u = torch.cat([torch.as_tensor(test_pos_u), torch.as_tensor(test_neg_u)])\n",
    "test_v = torch.cat([torch.as_tensor(test_pos_v), torch.as_tensor(test_neg_v)])\n",
    "test_label = torch.cat([torch.zeros(len(test_pos_u)), torch.ones(len(test_neg_u))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# input layer : 5\n",
    "# hidden layer : 16\n",
    "net = GraphSAGE(5, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\di\\anaconda3\\envs\\venv_gnn\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In peoch 0, loss: 0.6724940538406372\n",
      "In peoch 5, loss: 0.5050308704376221\n",
      "In peoch 10, loss: 0.38803035020828247\n",
      "In peoch 15, loss: 0.34129464626312256\n",
      "In peoch 20, loss: 0.3013409376144409\n",
      "In peoch 25, loss: 0.26346445083618164\n",
      "In peoch 30, loss: 0.23212091624736786\n",
      "In peoch 35, loss: 0.19596540927886963\n",
      "In peoch 40, loss: 0.15028861165046692\n",
      "In peoch 45, loss: 0.10778073966503143\n",
      "In peoch 50, loss: 0.07224243879318237\n",
      "In peoch 55, loss: 0.04359419643878937\n",
      "In peoch 60, loss: 0.02438025176525116\n",
      "In peoch 65, loss: 0.013142098672688007\n",
      "In peoch 70, loss: 0.006081700790673494\n",
      "In peoch 75, loss: 0.0024116893764585257\n",
      "In peoch 80, loss: 0.0011544295120984316\n",
      "In peoch 85, loss: 0.0006790601182729006\n",
      "In peoch 90, loss: 0.0004566108400467783\n",
      "In peoch 95, loss: 0.00033353964681737125\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), node_embed.parameters()), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    logits = net(g, inputs)\n",
    "    pred = torch.sigmoid((logits[train_u] * logits[train_v]).sum(dim=1))\n",
    "\n",
    "    loss = F.binary_cross_entropy(pred, train_label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    all_logits.append(logits.detach())\n",
    "\n",
    "    if e % 5 == 0: \n",
    "        print('In peoch {}, loss: {}'.format(e, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.86\n"
     ]
    }
   ],
   "source": [
    "pred = torch.sigmoid((logits[test_u] * logits[test_v]).sum(dim=1))\n",
    "print('Accuracy', ((pred >= 0.5) == test_label).sum().item() / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv_gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bda2e7c1864eec52fbc66237ae3f31391aae09a1aea123b18e8e0a87a7474b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
